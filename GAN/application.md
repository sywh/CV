# application
## image translation
### base
- 定义：图像翻译，指从一副图像到另一副图像的转换。可以类比机器翻译，从一种语言转换为另一种语言。
- 常见图像翻译任务
  - 图像去噪
  - 图像超分辨
  - 图像补全
  - 风格迁移
- 分类
  - 有监督图像翻译：原始域与目标域存在一一对应数据
  - 无监督图像翻译：原始域与目标域不存在一一对应数据
### pix2pix
- 设计
  - 直观想法：设计一个CNN网路，直接建立输入-输出的映射，就像图像去噪问题一样。
    - 问题：生成图像质量不清晰
    - 原因：比如分割图->街景图，语义分割图的每个标签比如"汽车"可能对应不同样式、颜色的汽车，那么模型学习到的会是所有不同汽车的平均，这样会造成模糊
  - pix2pix
    - 思路：在上述直观想法的基础上加入一个判别器，判断输入图片是否是真实样本。通过加入GAN的loss去惩罚模型, 解决生成图像的模糊问题
    - 基于CGAN：和CGAN有所不同，输入只有条件信息。原始的CGAN需要输入随机噪声，以及条件。之所以没有输入噪声信息，是因为在实际实验中，噪声往往被淹没在条件当中，所以这里直接省去了。
    - loss:
      - GAN loss：LSGAN的最小二乘loss，并使用PatchGAN来进一步保证生成图像的清晰度。PatchGAN将图像划分成很多个Patch，并对每一个Patch使用判别器进行判别（实际代码实现有更取巧的办法），将所有Patch的loss求平均作为最终的loss
      - 输出和标签的L1 loss：采用L1 loss而不是L2 loss的理由很简单：L1 loss相比L2 loss保边缘(L1 loss基于拉普拉斯先验，L2 loss基于高斯先验)
    - 测试时也使用Dropout，以使输出多样化
- 问题
  - 如何生成高分辨率图像和高分辨率视频
    - 在pix2pix这一通用的图像翻译框架上，利用更好的网络结构以及更多的先验
    - pix2pixHD：提出用多尺度的生成器和判别器，来生成高分辨率的图像
    - vid2vid：在pix2pixHD基础上，利用光流、时序约束等生成高分辨率视频。
  - 有监督图像翻译的缺点
    - 需要一一对应的图像
### CycleGAN
- 思路：
  - 假设有两个域的数据，记为A，B。如A域是普通的马，B域是斑马。A->B的转换缺乏监督信息
  - 对于A域的所有图像，学习一个网络Generator A2B，生成B域的图像；对于B域的所有图像，学习一个网络Generator B2A，生成A域的图像
  - 通过A->fake_B->rec_A，以及B->fake_A->rec_B，可以设计重建损失。其中A->fake_B和fake_A->rec_B的网络是一模一样的
- 训练过程分两步：
  - 对于A域的某张图像，送入Generator A2B，生成fake_B；
  - 将fake_B送入Generator B2A，得到重构后的图像rec_A
  - 将重构后的图像rec_A和原图A做均方误差，实现了有监督的训练
- 网络结构
  - cycleGAN的生成器采用U-Net，判别器采用LSGAN
- loss
  - A域和B域的GAN loss，以及Cycle consistency loss
  - 公式：
  - 整个过程end to end训练，效果非常惊艳，利用这一框架可以完成非常多有趣的任务。
### StarGAN
- 关注问题：
  - cycleGAN需要针对每一对域训练一个模型，效率太低
  - cycleGAN对每一个域都需要搜集大量数据。以橘子转换为红苹果和青苹果为例，不管是红苹果还是青苹果，都是苹果，只是颜色不一样而已，这两个任务信息是可以共享的，没必要分别训练两个模型。
- 思路：
  - balabala
- 优点
  - 提出多领域无监督图像翻译框架，实现了多个领域的图像转换
  - 不同领域的数据可以混合在一起训练，提高了数据利用率
## 文本生成
### GAN为什么不适合文本任务
### seqGAN用于文本生成
## others
### 数据增广
- 行人重识别
  - 难点：不同摄像头下拍摄的人物环境、角度差别非常大，导致承载较大的domain gap。
  - 解决方案：考虑使用cycleGAN来生成不同摄像头下的数据进行数据增广。对于每一对摄像头都训练一个cycleGAN，这样就可以实现将一个摄像头下的数据转换成另一个摄像头下的数据，但是内容（人物）保持不变。
  - paper
    - Zheng Z , Zheng L , Yang Y . Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in Vitro[C]// 2017 IEEE International Conference on Computer Vision (ICCV). IEEE Computer Society, 2017.
    - Zheng, Z., Yang, X., Yu, Z., Zheng, L., Yang, Y., & Kautz, J. Joint discriminative and generative learning for person re-identification. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)[C]. 2019.
### 图像超分辨与图像补全
- 作为图像翻译问题，训练一个端到端的网络，输入是原始图片，输出是超分辨率后的图片，或者是补全后的图片
- 超分辨率：
  - paper: Ledig C , Theis L , Huszar F , et al. Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network[J]. CVPR, 2016.
  - 思路：增加判别器，使得超分辨率模型输出的图片更加清晰，更符合人眼主观感受
- 图像补全
  - paper: Iizuka S , Simo-Serra E , Ishikawa H . Globally and locally consistent image completion[J]. ACM Transactions on Graphics, 2017, 36(4):1-14.
  - 思路：全局+局部一致性的GAN实现图像补全，使得修复后的图像不仅细节清晰，且具有整体一致性。
### 语音领域
- 音频去噪：SEGAN，缓解了传统方法支持噪声种类稀少，泛化能力不强的问题
- 语音增强：提高了ASR系统的识别率