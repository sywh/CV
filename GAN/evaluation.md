# evaluation
## subjective
- 主观评价需要花费大量人力物力
- 主观评价带有主观色彩，且有些badcase没看到容易造成误判
- 如果GAN过拟合，那么生成的样本会非常真实，人类主观评价得分会非常高，可这并不是一个好的GAN（是指多样性不够吗？）
## inception score
- 公式：
- 理解：对于一个在ImageNet上训练良好的GAN，其生成的样本丢给Inception网络(在ImageNet上预训练的Inception Network V3网络，Inception一词就是来源于此)进行测试时，得到的判别概率应该具有如下特性：
  - 第一个出发点是清晰度：生成的每张图片x应该有清晰可辨的物体 →对于一个清晰的图片，把它输入InceptionNet，那么它属于某一类的概率应该非常大，而属于其它类的概率应该很小，故分布很集中。具体到ImageNet上，把生成的图片x输入到 Inception V3，得到一个 1000 维的向量 y，这个向量的某个维度值格外大，而其余的维度值格外小（也就是概率分布图十分尖）。对同一个类别的图片，其输出的概率分布应该趋向于一个脉冲分布，可以保证生成样本的准确性
  - 第二个出发点是多样性：好的生成器生成的样本应保证语义多样性，对在ImageNet上训练的生成器而言，生成的图片涵盖的类别应该越多越好。假设生成了 10000 张图片，那么最理想的情况是，1000类中每类生成了10张。 也就是说，边缘分布p(y)理想的分布是均匀分布。P(y)的计算，N个生成的图片（N 通常取50k），每个生成图片都输入到 Inception V3 中，各自得到一个自己的概率分布向量，把这些向量求一个平均，得到生成器生成的图片全体在所有类别上的边缘分布。对于所有类别，其输出的概率分布应该趋向于一个均匀分布，这样才不会出现mode dropping等，可以保证生成样本的多样性
  - 实际实验表明，IS和人的主观判别趋向一致
  - 由于p(y|x)我们希望有一个很集中的分布，而p(y)我们希望是一个很均匀的分布，也就是说我们希望这两个分布之间的距离越大越好，KL散度可以刻画分布差异，所以我们希望它尽可能大。一个训练良好的GAN, p(y|x)接近脉冲分布，p(y)趋近于均匀分布，两者KL散度会很大，Inception Score自然就高，所以Inception Score越大越好。
  - IS的计算没有用到真实数据
- 特点：可以一定程度上衡量生成样本的多样性和准确性，但是无法检测过拟合（GAN的过拟合指什么？）。mode score也是如此。不推荐在和ImageNet数据集差别比较大的数据上使用。
### (dis)advantage
- 优点
- 缺点
  - KL散度的问题：KL 散度用以衡量两个概率分布的距离，它是非负的，值越大说明这两个概率分布越不像。但这个距离不是对称的，观察公式，  很大  很小的地方对 KL 距离贡献很大，而  很小  很大的地方对 KL 距离的贡献很小。我们预期  的某个维度值很大，而  总体均匀，因此需要把 放在公式 (2) 中双竖线的前面。放到后面可能会造成 的极端值被忽略，而正是这个极端值的存在告诉了我们这个生成的图片是否清晰
  - 举例：若生成器可生成1000类，但对每一类都只生成相同的sample，而且这个sample分类分数很高的话，那么Inception Score会很高，但这不是好的生成器，因为对每一类，没有生成多样性的sample
## mode score
- 公式
- 理解：作为inception score的改进版本，添加了关于生成样本和真实样本预测概率分布相似性度量一项
## kernel MMD(Maximum Mean Discrepancy)
- 推荐了解
## wasserstein distance
- 公式：
- 理解：
  - wasserstein distance在最优传输问题中通常叫做推土机距离
  - wasserstein distance可以衡量两个分布之间的相似性。距离越小，分布越相似。
- 特定：如果特征空间选择合适，会有一定的效果。但是计算复杂度为O(n^3)太高
## Frechet Inception Distance(FID)
- 公式：
- 理解：
  - FID距离计算真实样本，生成样本在特征空间上的距离
  - 首先利用Inception网络提取特征，然后使用高斯模型对特征空间进行建模。根据高斯模型的均值和协方差来进行距离计算
- 特点：
  - 尽管只计算了特征空间的前两阶矩，但是鲁棒，且计算高效
  - 与IS相比，FID不依赖Inception Net判断图片的类别，而是提取feature层，判断真实数据和生成样本在feature层面的距离。但其涉及的深层次原理比较复杂，没有Inception Score那么直观
  - FID越小则说明模型越好，而IS越大说明模型越好
### (dis)advantage
- 优点
  - Inception Score那种每个类别内部只产生一模一样的图片这种形式，在FID里可以处理(为什么？)
- 缺点
## 1-Nearest Neighbor classifier
- 使用留一法，结合1-NN分类器（别的也行）计算真实图片，生成图片的精度。如果两者接近，则精度接近50%，否则接近0%
- 对于GAN的评价问题，作者分别用正样本的分类精度，生成样本的分类精度来衡量生成样本的真实性，多样性
  - 对于真实样本xr，进行1-NN分类的时候，如果生成的样本越真实，则真实样本空间R将被生成样本xg包围，那么xr的精度会很低。
  - 对于生成样本xg，进行1-NN分类的时候，如果生成的样本多样性不足，由于生成的样本聚在几个mode，则xg就很容易和xr区分，导致精度会很高。
- 特点：理想的度量指标，可以检测过拟合。
## others
- AIS，KDE方法也可以用于评价GAN，但这些方法不是model agnostic metrics。也就是说，这些评价指标的计算无法只利用：生成样本和真实样本来计算。
## problem
- inception公式的含义？KL散度？两个分布的含义？KL散度的问题
- inception和FID的对比？
