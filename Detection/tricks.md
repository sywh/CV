# tricks
## Data Augmentation
- 过拟合
  - 验证过拟合的方法：画出loss曲线，如果训练集loss持续减小但验证集loss增大，就说明是过拟合了
- 数据增强目的
  - 通过数据增强实现数据更复杂的表征，从而减小验证集和训练集以及最终测试集的差距，让网络更好地学习迁移数据集上的数据分布。这也说明网络不是真正地理解数据，而是记忆数据分布
- 数据增强的方法
  - 数据变换增强：包括几何变换，色彩空间变换，随机擦除，对抗训练，神经风格迁移等
  - 重采样增强：主要侧重于新的实例合成，如图像混合(mixup)，特征空间的增强，GAN生成图片
- 图像变换增强
  - 几何变换
    - Flipping：要衡量普遍性，这种变换对数字数据集不具有安全性
    - **Cropping**：通常在输入图片的尺寸不一时，会进行按中心的裁剪操作。裁剪某种程度上和平移操作有相似性（体现在哪？）。根据裁剪幅度变化，该操作具有一定的不安全性
    - Rotation：大幅度的旋转对数字集会有不安全性的考虑。
    - Translation：平移也需要合理设计。如车站人脸检测，只需要中心检测时，就可以加合适的平移增强。平移后空出部分填0或者255，或用高斯分布噪声。
    - Noise injection：在像素上叠加高斯分布的随机噪声。
    - 实验中，随机裁剪的效果最好
  - 颜色空间变换
    - 原因：实际图像中一定存在光线偏差，所以光线的增强十分有必要。但因为光线的复杂度较高，数据样本远远不够，光线增强效果往往不如几何。颜色变换的增强方法是从色彩空间角度拟合偏置（拟合偏置这个说法还挺新颖的）
    - 方法：
      - 像素限制、像素矩阵变换、像素值颠倒
      - 直方图变换增强
      - 转灰度图：灰度图和彩图相比，计算时间成本大大减少，但精度会下降一些，因为特征的维度下降了
      - 转颜色空间：将RGB映射到其它色彩空间进行学习，如YUV、CMY、HSV等
      - 参考 A Preliminary Study on Data Augmentation of Deep Learning for Image Classification
    - 缺点：
      - 计算量大、内存消耗
      - 不安全性：比如识别人脸的关键信息是黄白黑，但是大量增强出红绿蓝，会丢信息
    - 效果有限的可能原因
      - 真实世界几何多样性比颜色简单
      - 色彩的变化多样性更多，导致增强不够，反而学不好，颜色空间欠拟合
      - 变换不安全
- 几何变换 vs 颜色变换
  - Kernel filter
    - 滤波器核在图像处理中用的比较广，这里提到用这种方法来增强
    - 正则化增强方法PatchShuffle：在一个patch内随机交换像素值，使得对噪声的抵抗更强，以避免过拟合
    - 应用滤波器增强的工作不多，因为这种方法其实和CNN的机制一样，这么做或许还不如直接在原始CNN上加深网络
  - Mixing images
    - mixup：直接均值相加混合
    - 非线性的mixup裁剪
    - 随机裁剪的图像混合
    - 总结：这些混合方式是十分反人类直觉的，因此可解释性不强。只能说是可能增强了对底层低级特征如线条边缘等的鲁棒性，其实有点没有抓住关键点
  - Random erasing
    - 随机擦除类似cutout思想，通过mask的遮挡使得网络能够提高遮挡情况的鲁棒性
    - 需要手工设计的部分包括mask的大小以及生成方式
    - 是一种比较有效的方法，但这种方法也需要考量增强的安全性，比如MNIST数据集的数字8 在cutout后可能出问题
  - 注意：组合的增强方式往往是连续变化的，导致数据集的容量会迅速扩大，这对于小数据集领域来说容易发生过拟合（为什么容易过拟合？），所以需要设计合理的搜索算法得到恰当的训练数据集
- 基于深度学习的数据增强
  - Feature space augmentation
    - 基于SMOTE类别不平衡的过采样法来进行特征空间的插值操作，进行数据增强
    - 就实验结果而言不算特别出众
  - Adversarial training
    - 对抗样本训练可以提高鲁棒性，但实际应用中提高不一定明显，因为自然对抗样本的数目没有那么多
    - NIPS的对抗攻击大赛很多从神经网络的学习策略下手，进行梯度攻击，更加偏向于认为的攻击了，对于普适的检测性能提高意义反而不大，更强调安全需求高的场合
  - GAN-based data augmentation
  - Neural Style Transfer
    - 不觉得这个效果会普遍很好，应该来说是针对特定域会有效（如白天黑夜），实际效果应该有限
  - Meta learning data augmentation
    - Neural augmentation
    - Smart augmentation：和neural augmentation差不多，随机采样类内图片进行通道叠加，然后输出融合图像，通过梯度下降使得输出图像的类内差距减小（没考虑类间关系，可能也不便处理）
  - AugoAugment
    - 谷歌最早做的自学习增强方法，走的NAS的思路，RL+RNN搜索增强空间
    - 搜索空间太大，复现搜索过于依赖硬件条件
- 设计数据增强的考虑
  - 测试阶段数据增强：许多论文指出在测试阶段进行同等数据增强能获得较好的效果，归结为训练测试阶段的一致性。但是，这种手段时间成本太高，只在如医学影像等追求精度的关键领域可以使用
  - 课程学习：Bengio早年在ICML提出的观点，提出在训练早期，给简单样本的权重最高，随着训练过程的持续，较难样本的权重将会逐渐被调高
  - 高分辨率的影响：高清(1920*1080*3)或4K(3840*2160*3)等高分辨率图像需要更多的处理和内存来训练CNN，然而下一代模型更倾向于使用这样更高分辨率的图像，因为模型中常用的下采样会造成图像中信息的丢失，使图像识别更困难。研究人员发现，高分辨率图像和低分辨率图像一起训练的模型，比单独的任何一个模型都要好。有实验在256×256图像和512×512图像上训练的模型分别获得7.96%和7.42%的top-5 error，汇总后，他们的top-5 error变低，为6.97%。随着超分辨率网络的发展，将图像放大到更高的分辨率后训练模型，能够得到更好更健壮的图像分类器。
  - 最终的数据集大小：数据增强的形式可分为在线和离线增强。前者是子啊加载数据时增强，可能造成额外的内存消耗（现在都是数据容量不变的随机增强）。此外作者提出，当前数据集尤其是进行增广后的数据集是十分胖蛋的，明显能在一定程度上缩小数据集但保持性能下降不多。
  - 通过数据增强减轻类别不平衡：通过增强在一定程度上解决类别不平衡问题，但增强需要仔细设计，否则会对已经学习较好的类别或场景造成过拟合等问题。
- 参考论文
  - A survey on Image Data Augmentation for Deep Learning
## OHEM
## NMS
## Multi Scale Training/Testing
## small object with context
## relation network
## GAN
## attention
## Others
- 简介
  - 摘要声称的5%是对单阶段YOLOv3的提升
  - 单阶段没有RoIPooling阶段，很多性质确实不如两阶段，因此采用trick很有必要
  - 两阶段本身结构由于单阶段，所以外加的trick提供的如不变性等，网络自身能够学习和适应，就不起作用了
- trick
  - Visually Coherent Image Mixup for Object Detection:
    - 图像分类中的mixup方法：作用是提供训练的正则化，通过对图像进行mixup得到合成图，然后将标签的one-hot编码也做类似处理得到新的标签
    - 叠加代替缩放：相比于分类的resize，为了保证检测图像不畸变影响效果，作者选择直接叠加，取最大的宽高，空白进行灰度填充，不进行缩放
    - 选择ab较大（如1.5，1.5）的beta分布作为系数来混合图像，作者说是相干性视觉图像的更强。loss是两张图像物体的loss之和，loss权重分别是beta分布的系数
  - Classification Head Label Smoothing
    - 标签平滑在检测的分类任务中常用到，最早是在InceptionV2中提出
    - 如果标签中有的是错的，或者不准，会导致网络过分新人标签而一起错下去。为了提高网络的泛化能力，避免这种错误，在one-hot的label计算loss时，真值类别位置乘以一个系数(1-e)，e很小如0.05；非标注的类别原来为0，现在改为e=0.05送进去算loss。网络的优化方向不便，但是相比0-1 label会更加平滑
    - 这里进一步改进了一下label smooth，在原来基础上除以了类别数
    - 标签平滑参考：https://juejin.im/post/5a29fd4051882534af25dc92
  - Data Preprocessing
    - 数据增强，分为几何变换和色彩变换，这么分类区别其实是是否变换label
    - 但是，将真实世界就这么简单地分解过于粗糙了
    - 谷歌的增强考虑到了如何学习检测任务的增强，但也只是加了bbox_only的增强，效果一般；就实际来说，合理性和有效性有待商榷
    - 作者认为，两阶段的RPN生成就是对输入的任意裁剪，所以这个增强就够了。虽然两阶段能提供一些不变性，但用了一般来说都是更好的
  - Training Schedule Revampling
    - 训练策略上，warmup + 余弦学习率调整
  - Synchronized Batch Normalization
    - 跨多卡同步正则化
  - Random shapes training for single-stage object detection networks
    - 多尺度训练，每经过一定的iteration更换一种尺度，举例是YOLOv3的尺度范围
    - 多尺度训练/测试到底包含哪些方式？
- 参考论文
  - Bag of Freebies for Training Object Detection Neural Networks