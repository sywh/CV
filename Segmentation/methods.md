# methods
## traditional
- 思路：为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入，用于训练和预测
- 缺点：
  - 存储开销大：对每个像素使用15×15的图像块，不断滑动窗口，将图像块输入到CNN中进行类别判断。因此，需要的存储空间随滑动窗口的次数和大小急剧上升？
  - 效率地下：相邻像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算有很大程度上的重复
  - 像素块的大小限制了感受野的大小：通常像素块的大小比整副图像的大小小很多，只能提取一些局部特征，从而导致分类性能受到限制
## FCN
### 思路
- 分类CNN：网络最后为全连接层，经过softmax后得到类别概率信息，但只能识别整个图片的类别，不能识别每个像素点的类别
- FCN：将后面几个全连接都换成卷积，这样就可以获得一张2维的feature map，后接softmax获得每个像素点的分类信息。通过对图像进行像素级的分类，实现语义级别的图像分割
### 结构
- 典型结构：
  - 反卷积层对最后一个卷积层的feature map进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每个像素进行预测
  - 跳级(skip)结构
    - 直接用最后一层feature map上采样，进行预测，得到的分割结果比较粗糙
    - 考虑加入更多前层的细节信息，也就是把倒数几层的输出和最后的输出做一个fusion，实际上就是加和，然后再上采样
    - 根据skip结构的不同，有三种网络，分别为FCN-32s，FCN-16s和FCN-8s
    - 实验表明，这样的分割结果更细致更准确，但逐层fusion过程中，做到第三层以后，结果又会变差，所以作者做到这里就停了
  - 最后一层尺寸最小的feature map叫做heatmap， 是最重要的高维特征图
### 优点
- FCN可以接受任意尺寸的输入图像
### 缺点
- 结果不够精细：FCN-8s虽然比FCN-32s的效果好了很多，但上采样的结果还是比较模糊和平滑，对图像中的细节不敏感
- 对每个像素进行分类，**没有充分考虑像素与像素之间的关系**。忽略了在通常的基于像素分类的分割方法中使用的**空间规整(spatial regularization)步骤**，缺乏空间一致性
### 讨论
#### 全连接层和卷积层如何相互转化
- 两者相互转换的可能性
  - 不同点：卷积层的神经元只与属于数据中的一个局部区域链接，并且卷积神经元共享参数
  - 相同点：都是计算点积，所以他们的函数形式是一样的
- 转换方法
  - 卷积层->全连接层：全连接层权重矩阵是一个巨大的矩阵，除了某些特定块，其余部分都是零。在其中大部分块中，元素都是相等的。
  - 全连接层->卷积层：VGG16中第一个全连接层是25088×4096，将输入reshape成7×7×512，将滤波器尺寸设置为和输入尺寸一致，则本质上和全连接层输出是一样的
- 例子
  - AlexNet: 227*227*3，卷积和下采样得到7×7×512，reshape以后，使用两个尺寸为4096的全连接层，最后有1000个神经元的全连接层计算分类评分
  - 第一个区域是7×7×512的全连接层，滤波器尺寸为7×7，输出1×1×4096
  - 第二个区域，滤波器尺寸为1×1，输出1×1×4096
  - 第三个区域，滤波器尺寸为1×1，输出1×1×1000
#### 为什么传统CNN的输入图片是固定大小
- 卷积层和池化层对输入图片大小没有要求
- 全连接层，feature map需要reshape成向量，向量中每个元素(n*n)作为一个结点都要与下一层的所有结点(4096)全连接，权值个数是4096×n×n。而神经网络结构一旦确定，它的权值个数就是固定的，所以n不能变化，层层往回看，输入图片大小要固定
#### 全连接层转化为卷积层的好处
- 输入图片大小不固定
- 相比于全连接层 + 滑窗计算，FCN能共享计算资源，计算要高效得多。
## U-Net
### 传统方法
- 生物医学图像处理领域
  - 目标输出应该包括目标类别的位置，并且每个像素都应该有类标签
  - 缺少训练图片
- Ciresan方法
  - 训练一个卷积神经网络，用滑动窗口提供像素的周围区域(patch)作为输入来预测每个像素的类标签
  - 优点
    - 输出结果可以定位出目标类别的位置
    - 由于输入的训练数据是patches，相当于进行了数据增广，解决了生物医学图像数量少的问题
  - 缺点
    - 慢：patch间重叠会有很多冗余计算，如果两个块重叠部分太多，卷积核权重会被同一些特征训练两次，造成资源浪费
    - 定位准确性和获取上下文信息不可兼得：打的patch需要更多的pooling达到全连接层的大小，pooling层越多，丢失的信息就越多，定位准确性越差；小的patch只能看到很小的局部信息，包含的背景信息不够
### U-Net方法
- 网络结构
  - 使用全卷积神经网络
  - 左侧网络是收缩路径：使用卷积和maxpooling
  - 右侧网络是扩张路径：上采样特征图与左侧收缩路径对应层特征图进行拼接
  - 两次反卷积后，再用两个1×1卷积，接softmax
## SegNet
- 网络结构
  - 包含encoder网络（提取高维特征）和对应的decoder网络（提升分辨率）
  - 解码网络使用最大池化层的池化索引进行非线性上采样，上采样过程就不需要学习
  - 上采样得到的稀疏图与滤波器卷积得到稠密的特征图
- 使用池化层索引进行上采样的优势
  - 提升边缘刻画度
  - 减少训练参数
  - 这种上采样模式可以包含到任何编码-解码网络中
- 算子
  - 最大池化：为了获得空间小位移的平移不变。最大池化损失了边缘细节，因此，在编码过程中保存边缘信息很重要。考虑到内存原因，只保存最大池化索引。
  - Decoder卷积：作用是为upsampling变大的图像丰富信息，使得在pooling过程丢失的信息可以通过学习在Decoder得到
- 优点：
  - 相比FCN：FCN解码模型需要存储编码特征图，在嵌入式设备中内存紧张
## RefineNet
- 网络结构
  - encoder：ResNet得到1/4, 1/8, 1/16, 1/32分辨率feature map
  - refineNet Block：将不同分辨率的feature map进行融合
  - 1/4分辨率融合feature map接softmax再双线性插值输出
- RefineNet block
  - Resudual convolution unit:
  - Multi-resolution fusion:
  - Chained residual pooling:
  - Output convolutions:
## PSPNet
- FCN问题
  - 没有采取合适的策略来利用全局的信息，不能利用好全局的场景线索。
    - 关系不匹配(Mismatched Relationship)
    - 易混淆的类别(Confusion Categories)
    - 不显眼的类别(Inconspicuous Classes)
  - 例子：没有发现左边的船屋，而把船误识别为车
- 思路
  - 借鉴SPPNet，设计PSPNet(pyramid scene parsing network)，通过金字塔池化集成困难的上下文特征
  - 加入额外的深度监督loss
- 优点：
  - 实现利用上下文信息的能力进行场景解析
## DeepLabv1
- DCNNs问题
  - DCNNs的高级特征具备平移不变性（根源在于重复的池化和下采样），导致DCNNs做语义分割时精准度不够
- 思路
  - 结合深度卷积神经网络(DCNNs)和概率图模型(DenseCRFs)的方法
  - 空洞卷积：针对下采样降低分辨率的问题，用空洞卷积算法扩展感受野，获取更多的上下文信息
  - 完全连接的条件随机场：提高模型捕获细节的能力
  - Multi-Scale：使用多个MLP结合多尺度特征解决，有助于提升预测结果，但效果不如CRF明显
## DeepLabv2
- 思路
  - DCNN连续池化和下采样造成分辨率降低：DeepLabv2在最后几个最大池化层中去除下采样，使用空洞卷积，以更高的采样密度计算特征映射
  - 物体存在多尺度：DeepLabv1使用多个MLP结合多尺度特征解决，增加了特征计算量和存储空间。受到SPP启发，提出类似结构：在给定的输入上以不同采样率的空洞卷积并行采样，相当于以多个比例捕捉图像的上下文，称为ASPP
  - DCNN的平移不变性/分类不变性影响空间精度：采样全连接CRF来增强模型捕捉细节的能力
- 性能
  - 速度：NVidia TitanX上8FPS
  - 精度：PASCAL VOC2012上79.7mIOU
## DeepLabv3
- 思路
  - 多种捕获多尺度信息的方式
    - Image Pyramid: 将输入图片缩放成不同比例，分别应用在DCNN上，将预测结果融合得到最终输出
    - Encoder-Decoder: 利用Encoder阶段的多尺度特征，运用到Decoder阶段上恢复空间分辨率，代表工作有FCN、SegNet、PSPNet等
    - Deeper w. Atrous COnvolution: 在原始模型的顶端增加额外的模块，如DenseCRF，捕捉像素间长距离信息
    - Spatial Pyramid Pooling：空间金字塔池化具有不同采样率和多种感受野的卷积核，能够以多尺度捕捉对象
- 对比
  - DeepLabv1-v2：使用带孔卷积提取密集特征来进行语义分割
  - DeppLabv3：
    - 为了解决分割对象的多尺度问题，设计采用多比例的带孔卷积级联或并行来捕获多尺度背景
    - 修改之前提出的带孔空间金字塔池化模块，用于探索多尺度卷积特征，将全局背景基于图像层次进行编码获得特征
- 性能
  - 精度：PASCAL VOC2012上79.7mIOU
## DeepLabv3+
- 语义分割关注的问题
  - 问题1：实例对象多尺度问题
  - 问题2：下采样导致分辨率下降，预测精度降低，造成边界信息丢失
- 解决方案
  - DeepLabv3设计的ASPP结构解决了问题1
  - DeepLabv3+主要目的在于解决问题2
- 问题2
  - 采用空洞卷积代替pooling层来获得分辨率更高的feature，但feature分辨率高会极大增加运算量
  - Encoder-Decoder with Atrous Convolution
    - 在DeepLabv3基础上加入解码器，DeepLabv3作为编码器
    - 解码器
      - 在编码器低层级选一个feature，**用1×1的卷积进行通道压缩，目的在于减少低层级的比重**
      - 将编码器的输出上采样，与低层级feature拼接后，再进行依次3×3卷积（细化作用），然后上采样，得到像素级预测
  - Modified Aligned Xception
    - Xception采用deepwise separable convolution代替标准卷积，这种结构能在更少参数更少计算量的情况下学到同样的信息
    - 这里考虑将原来的ResNet-101骨架换成Xception
## MaskRCNN
- 网络结构
  - 将ROIPooling替换为ROIAlign
  - 在边框识别的基础上添加分支网络，用于语义Mask识别(FCN层)
- 性能
  - 速度：5FPS，相对FasterRCNN仅增加一个小的Overhead
  - 精度：单模型SOTA，不借助trick
- 技术要点
  - 强化的基础网络：ResNeXt-101 + FPN作为特征提取网络
  - ROIAlign：采用ROIAlign代替ROIPooling，使用双线性插值，很大程度上解决了仅通过Pooling带来的MisAlignment对齐问题(虽然MisAlignment在分类问题上影响不打，但在Pixel级别的Mask上会存在较大误差), stride越大，ROIAlign的改进越明显
  - Loss function：
    - 每个ROIAlign对应K*m^2维度的输出，K为类别个数，即输出K个mask，m为池化分辨率
    - 采用K个mask：**通过对每个class对应一个Mask可以有效避免类间竞争（其它class不贡献loss）**
    - 
- 优点
  - 可以方便地拓展到其它任务，比如人的姿态估计
  - Mask分支可以和多种RCNN框架(基于ResNet的，和基于FPN的)结合
# 基于弱监督学习的图像分割
# 全景分割